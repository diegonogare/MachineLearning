{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/diegonogare/MachineLearning/blob/main/5.5-MNIST_GAN.ipynb",
      "authorship_tag": "ABX9TyMlvUux/YnZs8YzpHubNK5V"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Treinar a rede GAN para gerar novos digitos\n",
        "\n",
        "Código adaptado de https://github.com/Zackory/Keras-MNIST-GAN/blob/master/mnist_gan.py"
      ],
      "metadata": {
        "id": "25dDKEMx0KL8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Am5PIHUC0Cp9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "from keras.layers import Input\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers.core import Reshape, Dense, Dropout, Flatten\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers.convolutional import Convolution2D, UpSampling2D\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.datasets import mnist\n",
        "from keras.optimizers import Adam\n",
        "from keras import backend as K\n",
        "from keras import initializers\n",
        "\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1000)\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train = (X_train.astype(np.float32) - 127.5)/127.5\n",
        "X_train = X_train.reshape(60000, 784)\n",
        "\n",
        "adam = Adam(learning_rate=0.0002, beta_1=0.5)"
      ],
      "metadata": {
        "id": "0nbV7JSc0kgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "randomDim = 100\n",
        "adam = Adam(learning_rate=0.0002, beta_1=0.5)"
      ],
      "metadata": {
        "id": "cBKc4ern1Gac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = Sequential()\n",
        "generator.add(Dense(256, input_dim=randomDim, kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n",
        "generator.add(LeakyReLU(0.2))\n",
        "generator.add(Dense(512))\n",
        "generator.add(LeakyReLU(0.2))\n",
        "generator.add(Dense(1024))\n",
        "generator.add(LeakyReLU(0.2))\n",
        "generator.add(Dense(784, activation='tanh'))\n",
        "generator.compile(loss='binary_crossentropy', optimizer=adam)"
      ],
      "metadata": {
        "id": "YASk6fSS1W_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator = Sequential()\n",
        "discriminator.add(Dense(1024, input_dim=784, kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n",
        "discriminator.add(LeakyReLU(0.2))\n",
        "discriminator.add(Dropout(0.3))\n",
        "discriminator.add(Dense(512))\n",
        "discriminator.add(LeakyReLU(0.2))\n",
        "discriminator.add(Dropout(0.3))\n",
        "discriminator.add(Dense(256))\n",
        "discriminator.add(LeakyReLU(0.2))\n",
        "discriminator.add(Dropout(0.3))\n",
        "discriminator.add(Dense(1, activation='sigmoid'))\n",
        "discriminator.compile(loss='binary_crossentropy', optimizer=adam)"
      ],
      "metadata": {
        "id": "jzbQuiYPZxkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator.trainable = False\n",
        "ganInput = Input(shape=(randomDim,))\n",
        "x = generator(ganInput)\n",
        "ganOutput = discriminator(x)\n",
        "gan = Model(inputs=ganInput, outputs=ganOutput)\n",
        "gan.compile(loss='binary_crossentropy', optimizer=adam)\n",
        "\n",
        "dLosses = []\n",
        "gLosses = []"
      ],
      "metadata": {
        "id": "HlrnzuaKZxa0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plotLoss():\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.plot(dLosses, label='Discriminitive loss')\n",
        "    plt.plot(gLosses, label='Generative loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.savefig(\"/content/drive/MyDrive/Digitos_GAN/Funcao_Perda.png\")"
      ],
      "metadata": {
        "id": "Cf8prOt51XF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plotGeneratedImages(epoch, examples=100, dim=(10, 10), figsize=(10, 10)):\n",
        "    noise = np.random.normal(0, 1, size=[examples, randomDim])\n",
        "    generatedImages = generator.predict(noise)\n",
        "    generatedImages = generatedImages.reshape(examples, 28, 28)\n",
        "\n",
        "    plt.figure(figsize=figsize)\n",
        "    for i in range(generatedImages.shape[0]):\n",
        "        plt.subplot(dim[0], dim[1], i+1)\n",
        "        plt.imshow(generatedImages[i], interpolation='nearest', cmap='gray_r')\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('/content/drive/MyDrive/Digitos_GAN/digito_gerado_%d.png' % epoch)"
      ],
      "metadata": {
        "id": "z9NrU-7lXh8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def saveModels():\n",
        "    generator.save('/content/drive/MyDrive/Digitos_GAN/gerador.h5')\n",
        "    discriminator.save('/content/drive/MyDrive/Digitos_GAN/discriminador.h5')"
      ],
      "metadata": {
        "id": "fA_0uywNPc35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epochs=1, batchSize=128):\n",
        "    batchCount = int(X_train.shape[0] / batchSize)\n",
        "    print('Épocas:', epochs)\n",
        "    print('Batch size:', batchSize)\n",
        "    print('Batch por épocas:', batchCount)\n",
        "\n",
        "    for e in range(1, epochs+1):\n",
        "        print('-'*15, 'Época %d' % e, '-'*15)\n",
        "        for _ in  tqdm(range(batchCount)):\n",
        "            noise = np.random.normal(0, 1, size=[batchSize, randomDim])\n",
        "            imageBatch = X_train[np.random.randint(0, X_train.shape[0], size=batchSize)]\n",
        "\n",
        "            generatedImages = generator.predict(noise, verbose=0)\n",
        "            X = np.concatenate([imageBatch, generatedImages])\n",
        "\n",
        "            yDis = np.zeros(2*batchSize)\n",
        "            yDis[:batchSize] = 0.9\n",
        "\n",
        "            discriminator.trainable = True\n",
        "            dloss = discriminator.train_on_batch(X, yDis)\n",
        "\n",
        "            noise = np.random.normal(0, 1, size=[batchSize, randomDim])\n",
        "            yGen = np.ones(batchSize)\n",
        "            discriminator.trainable = False\n",
        "            gloss = gan.train_on_batch(noise, yGen)\n",
        "        \n",
        "        dLosses.append(dloss)\n",
        "        gLosses.append(gloss)\n",
        "\n",
        "        plotGeneratedImages(e)"
      ],
      "metadata": {
        "id": "XG2MEfi1WQV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(100, 128)"
      ],
      "metadata": {
        "id": "3lw0fqSv1rRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plotLoss()"
      ],
      "metadata": {
        "id": "iWEiFHEtZHvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "saveModels()"
      ],
      "metadata": {
        "id": "CZj4HlaWAU-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gerar_digito(n_ex=1, dim=(1, 10), figsize=(12, 2)):\n",
        "    noise = np.random.normal(0, 1, size=(n_ex, randomDim))\n",
        "    imagem_gerada = generator.predict(noise)\n",
        "    imagem_gerada = imagem_gerada.reshape(28, 28)\n",
        "\n",
        "    plt.imshow(imagem_gerada, interpolation='nearest', cmap='gray_r')\n",
        "    plt.figure(figsize=figsize)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "1no7DalaWabQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gerar_digito()"
      ],
      "metadata": {
        "id": "qGTCVhprWctz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}