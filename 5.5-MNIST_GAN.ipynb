{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "25dDKEMx0KL8"
   },
   "source": [
    "#Usando GAN para gerar novos digitos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Am5PIHUC0Cp9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.layers import Input\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.datasets import mnist\n",
    "from keras.optimizers import Adam\n",
    "from keras import initializers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "LpciGJ_D0dnq"
   },
   "outputs": [],
   "source": [
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "np.random.seed(42)\n",
    "random_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "0nbV7JSc0kgT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = (X_train.astype(np.float32) - 127.5)/127.5  \n",
    "X_train = X_train.reshape(60000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "cBKc4ern1Gac"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\diego nogare\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "otimizador = Adam(lr=0.0002, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "YASk6fSS1W_g"
   },
   "outputs": [],
   "source": [
    "gerador = Sequential()\n",
    "gerador.add(Dense(256, input_dim=random_dim, kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n",
    "gerador.add(LeakyReLU(0.2))\n",
    "\n",
    "gerador.add(Dense(512))\n",
    "gerador.add(LeakyReLU(0.2))\n",
    "\n",
    "gerador.add(Dense(1024))\n",
    "gerador.add(LeakyReLU(0.2))\n",
    "\n",
    "gerador.add(Dense(784, activation='tanh'))\n",
    "gerador.compile(loss='binary_crossentropy', optimizer=otimizador)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Cf8prOt51XF-"
   },
   "outputs": [],
   "source": [
    "discriminador = Sequential()\n",
    "discriminador.add(Dense(1024, input_dim=784, kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n",
    "discriminador.add(LeakyReLU(0.2))\n",
    "discriminador.add(Dropout(0.3))\n",
    "\n",
    "discriminador.add(Dense(512))\n",
    "discriminador.add(LeakyReLU(0.2))\n",
    "discriminador.add(Dropout(0.3))\n",
    "\n",
    "discriminador.add(Dense(256))\n",
    "discriminador.add(LeakyReLU(0.2))\n",
    "discriminador.add(Dropout(0.3))\n",
    "\n",
    "discriminador.add(Dense(1, activation='sigmoid'))\n",
    "discriminador.compile(loss='binary_crossentropy', optimizer=otimizador)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3lw0fqSv1rRp"
   },
   "outputs": [],
   "source": [
    "def gerar_gan(discriminador, randomDim, gerador, otimizador):\n",
    "  discriminador.trainable = False\n",
    "  gan_input = Input(shape=(random_dim,))\n",
    "  x = gerador(gan_input)\n",
    "\n",
    "  gan_output = discriminador(x)\n",
    "  gan = Model(inputs=gan_input, outputs=gan_output)\n",
    "  gan.compile(loss='binary_crossentropy', optimizer=otimizador)\n",
    "\n",
    "  return gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "LX9DS__G1rUZ"
   },
   "outputs": [],
   "source": [
    "def salvar_digito_gerado(epoca, exemplos=25, dim=(5, 5), figsize=(10, 10)):\n",
    "    noise = np.random.normal(0, 1, size=[exemplos, random_dim])\n",
    "    imagem_gerada = gerador.predict(noise)\n",
    "    imagem_gerada = imagem_gerada.reshape(exemplos, 28, 28)\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(imagem_gerada.shape[0]):\n",
    "        plt.subplot(dim[0], dim[1], i+1)\n",
    "        plt.imshow(imagem_gerada[i], interpolation='nearest', cmap='gray_r')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('digitos\\gan_digito_gerado_epoca_%d.png' % epoca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q3OHMhVV1rXB"
   },
   "outputs": [],
   "source": [
    "epochs = 400\n",
    "batchSize = 128\n",
    "\n",
    "gLosses = []\n",
    "dLosses = []\n",
    "\n",
    "batch_count = X_train.shape[0] / batchSize\n",
    "\n",
    "generator = gerador\n",
    "gan = gerar_gan(discriminador, random_dim, gerador, otimizador)\n",
    "\n",
    "batchCount = X_train.shape[0] / batchSize\n",
    "print('Épocas:', epochs)\n",
    "print('Batch size:', batchSize)\n",
    "print('Batches por época:', batchCount)\n",
    "\n",
    "for e in range(1, epochs+1):\n",
    "    print('-'*15, 'Época %d' % e, '-'*15)\n",
    "\n",
    "    noise = np.random.normal(0, 1, size=[batchSize, random_dim])\n",
    "    imageBatch = X_train[np.random.randint(0, X_train.shape[0], size=batchSize)]\n",
    "\n",
    "    imagemGerada = gerador.predict(noise)\n",
    "    X = np.concatenate([imageBatch, imagemGerada])\n",
    "\n",
    "    yDis = np.zeros(2*batchSize)\n",
    "    yDis[:batchSize] = 0.9\n",
    "\n",
    "    discriminador.trainable = True\n",
    "    dloss = discriminador.train_on_batch(X, yDis)\n",
    "\n",
    "    yGen = np.ones(batchSize)\n",
    "    discriminador.trainable = False\n",
    "    gloss = gan.train_on_batch(noise, yGen)\n",
    "\n",
    "    gLosses.append(gloss)\n",
    "    dLosses.append(dloss)\n",
    "\n",
    "    salvar_digito_gerado(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "CZj4HlaWAU-s"
   },
   "outputs": [],
   "source": [
    "gerador.save('GAN_gerador_MNIST.h5')\n",
    "discriminador.save('GAN_discriminador_MNIST.h5')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMb5j1o3z/ty3czMSqEhiMb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
