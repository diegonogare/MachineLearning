{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/HmPr3S+BVZVQO4MK4qHm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Usando GAN para gerar novos digitos"
      ],
      "metadata": {
        "id": "25dDKEMx0KL8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Am5PIHUC0Cp9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "#from tqdm import tqdm\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.layers import Input\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers.core import Dense, Dropout\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.datasets import mnist\n",
        "from keras.optimizers import Adam\n",
        "from keras import initializers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "\n",
        "np.random.seed(42)\n",
        "random_dim = 100"
      ],
      "metadata": {
        "id": "LpciGJ_D0dnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train = (X_train.astype(np.float32) - 127.5)/127.5  \n",
        "X_train = X_train.reshape(60000, 784)"
      ],
      "metadata": {
        "id": "0nbV7JSc0kgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "otimizador = Adam(lr=0.0002, beta_1=0.5)"
      ],
      "metadata": {
        "id": "cBKc4ern1Gac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gerador = Sequential()\n",
        "gerador.add(Dense(256, input_dim=random_dim, kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n",
        "gerador.add(LeakyReLU(0.2))\n",
        "\n",
        "gerador.add(Dense(512))\n",
        "gerador.add(LeakyReLU(0.2))\n",
        "\n",
        "gerador.add(Dense(1024))\n",
        "gerador.add(LeakyReLU(0.2))\n",
        "\n",
        "gerador.add(Dense(784, activation='tanh'))\n",
        "gerador.compile(loss='binary_crossentropy', optimizer=otimizador)"
      ],
      "metadata": {
        "id": "YASk6fSS1W_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminador = Sequential()\n",
        "discriminador.add(Dense(1024, input_dim=784, kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n",
        "discriminador.add(LeakyReLU(0.2))\n",
        "discriminador.add(Dropout(0.3))\n",
        "\n",
        "discriminador.add(Dense(512))\n",
        "discriminador.add(LeakyReLU(0.2))\n",
        "discriminador.add(Dropout(0.3))\n",
        "\n",
        "discriminador.add(Dense(256))\n",
        "discriminador.add(LeakyReLU(0.2))\n",
        "discriminador.add(Dropout(0.3))\n",
        "\n",
        "discriminador.add(Dense(1, activation='sigmoid'))\n",
        "discriminador.compile(loss='binary_crossentropy', optimizer=otimizador)"
      ],
      "metadata": {
        "id": "Cf8prOt51XF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gerar_gan(discriminador, randomDim, gerador, otimizador):\n",
        "  discriminador.trainable = False\n",
        "  gan_input = Input(shape=(random_dim,))\n",
        "  x = gerador(gan_input)\n",
        "\n",
        "  gan_output = discriminador(x)\n",
        "  gan = Model(inputs=gan_input, outputs=gan_output)\n",
        "  gan.compile(loss='binary_crossentropy', optimizer=otimizador)\n",
        "\n",
        "  return gan"
      ],
      "metadata": {
        "id": "3lw0fqSv1rRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def salvar_digito_gerado(epoca, exemplos=25, dim=(5, 5), figsize=(10, 10)):\n",
        "    noise = np.random.normal(0, 1, size=[exemplos, random_dim])\n",
        "    imagem_gerada = gerador.predict(noise)\n",
        "    imagem_gerada = imagem_gerada.reshape(exemplos, 28, 28)\n",
        "\n",
        "    plt.figure(figsize=figsize)\n",
        "    for i in range(imagem_gerada.shape[0]):\n",
        "        plt.subplot(dim[0], dim[1], i+1)\n",
        "        plt.imshow(imagem_gerada[i], interpolation='nearest', cmap='gray_r')\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('gan_digito_gerado_epoca_%d.png' % epoca)"
      ],
      "metadata": {
        "id": "LX9DS__G1rUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 800\n",
        "batchSize = 128\n",
        "\n",
        "gLosses = []\n",
        "dLosses = []\n",
        "\n",
        "batch_count = X_train.shape[0] / batchSize\n",
        "\n",
        "generator = gerador\n",
        "gan = gerar_gan(discriminador, random_dim, gerador, otimizador)\n",
        "\n",
        "batchCount = X_train.shape[0] / batchSize\n",
        "print('Épocas:', epochs)\n",
        "print('Batch size:', batchSize)\n",
        "print('Batches por época:', batchCount)\n",
        "\n",
        "for e in range(1, epochs+1):\n",
        "    print('-'*15, 'Época %d' % e, '-'*15)\n",
        "\n",
        "    noise = np.random.normal(0, 1, size=[batchSize, random_dim])\n",
        "    imageBatch = X_train[np.random.randint(0, X_train.shape[0], size=batchSize)]\n",
        "\n",
        "    imagemGerada = gerador.predict(noise)\n",
        "    X = np.concatenate([imageBatch, imagemGerada])\n",
        "\n",
        "    yDis = np.zeros(2*batchSize)\n",
        "    yDis[:batchSize] = 0.9\n",
        "\n",
        "    discriminador.trainable = True\n",
        "    dloss = discriminador.train_on_batch(X, yDis)\n",
        "\n",
        "    yGen = np.ones(batchSize)\n",
        "    discriminador.trainable = False\n",
        "    gloss = gan.train_on_batch(noise, yGen)\n",
        "\n",
        "    gLosses.append(gloss)\n",
        "    dLosses.append(dloss)\n",
        "\n",
        "    salvar_digito_gerado(e)"
      ],
      "metadata": {
        "id": "q3OHMhVV1rXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gerador.save('GAN_gerador_MNIST.h5')\n",
        "discriminador.save('GAN_discriminador_MNIST.h5')"
      ],
      "metadata": {
        "id": "CZj4HlaWAU-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformar a imagem em um array de pixels"
      ],
      "metadata": {
        "id": "BmOhlIHXW5nP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_list = ['/content/1_gan_digito_gerado_1669689323.png']\n",
        "array_list = [np.squeeze(tf.keras.preprocessing.image.img_to_array(tf.keras.preprocessing.image.load_img(path, color_mode='grayscale')), axis=-1) for path in image_list]\n",
        "print(array_list[0])\n",
        "print(array_list[0].shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyFCrx7ZW4fJ",
        "outputId": "7b3446b3-a0e3-4b45-a399-0bd3802b3a29"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.\n",
            "  255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.]\n",
            " [255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.\n",
            "  255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.]\n",
            " [255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.\n",
            "  255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.]\n",
            " [255. 255. 255. 255. 255. 255. 255. 255. 190. 184. 255. 255. 255. 255.\n",
            "  255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.]\n",
            " [255. 255. 255. 255. 255. 255. 255. 255. 155. 145. 255. 255. 180. 225.\n",
            "  251. 154. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.]\n",
            " [255. 255. 255. 255. 255. 255. 255. 255. 247. 113. 157. 255. 192. 230.\n",
            "  252. 170. 255. 255. 255. 255. 255. 145. 255. 255. 255. 255. 255. 255.]\n",
            " [255. 255. 255. 255. 255. 255. 139. 216. 241.   0.  78. 255. 145.  57.\n",
            "  255. 205. 112. 255. 255. 255. 255.  57. 255. 255. 255. 255. 255. 255.]\n",
            " [255. 255. 255. 255. 253. 248. 103.   0.   0.   0.   0.   0.   0.   6.\n",
            "    7. 248. 179.   4. 181. 248.   7.  55. 138. 120. 250. 253. 255. 255.]\n",
            " [255. 255. 255. 255. 170.   0.   0.   0.   0.   0.   0.  34.  64. 212.\n",
            "    0.   0.   0.  96.  53.   0.   0.  50.   0. 120. 122. 202. 255. 255.]\n",
            " [255. 255. 255. 247. 123.   0.   0.   0.   0.   0.   0.  97. 184. 184.\n",
            "    2.  53.   0.   0.   0.  53.  71. 143.  31. 158. 255. 255. 255. 255.]\n",
            " [255. 255. 244. 127.  85.   0.   0.   0.   0.   0.  39. 128.  57.   0.\n",
            "  127.  96.  35.  64.  92. 223. 131.  28. 184. 195. 128. 220. 255. 255.]\n",
            " [255. 255. 249. 192. 170.   0.   0.   0.   0.   0.  78. 255. 113.   0.\n",
            "  253. 138.  20. 127. 102. 209.   7.  57. 255. 222. 184. 235. 255. 255.]\n",
            " [255. 255. 239.  64.  43.   0.   0.   0.   0.  16. 211. 154.  28.   0.\n",
            "   69. 239. 191. 128.  18.  48. 188.  57. 255. 255. 255. 255. 255. 255.]\n",
            " [255. 255. 254. 248. 182.  50.  21.   0.   0.  17. 145. 134. 110. 154.\n",
            "  243.  44.   7.   4.   0.   0.   7.  40.  95. 205. 240. 255. 255. 255.]\n",
            " [255. 255. 255. 255. 236. 198.  83.   0.   0.   0.   0. 135. 113.  44.\n",
            "  255. 191.   0.   0.   0.   0.   0. 154.   0.  27. 194. 255. 255. 255.]\n",
            " [255. 255. 255. 255. 208. 113. 113. 113.  19.   0.   0.  75.  63. 110.\n",
            "  145. 191.   0.   0.   0.   0.   0.   0.   0.  67. 220. 255. 255. 255.]\n",
            " [255. 255. 255. 255. 255. 255. 255. 255. 136.   0.  37.  57.   0.  94.\n",
            "  124. 191.   0.   0.   0.   0.   0.   0.   0.   0. 177. 255. 255. 255.]\n",
            " [255. 255. 255. 255. 255. 255. 255. 255. 103.   0.  78. 214. 177. 100.\n",
            "  250.  58.  49.  89.   0.   0.   0.   0.   0.  84. 231. 255. 255. 255.]\n",
            " [255. 255. 255. 255. 255. 255. 255. 255. 224.  19. 240. 132. 151.  57.\n",
            "   27. 175.   6.  11.   0.   0.   0.   0.   0.  10. 184. 255. 255. 255.]\n",
            " [255. 255. 255. 228.  80. 228. 230. 247. 252. 183.  75. 100.   8. 157.\n",
            "  193.  11.  55.  99.   0.   0.   0.   0.  19. 136. 251. 255. 255. 255.]\n",
            " [255. 255. 255. 232.  50. 124. 135. 215. 244.  50.  50.  50.  50.  11.\n",
            "   48.   0.   0.   0.   0.   0.   0.  11. 141. 255. 255. 255. 255. 255.]\n",
            " [255. 255. 255. 255. 255. 255. 255. 255. 249. 158. 255. 255. 196. 116.\n",
            "  148. 106.  77.   0.   0.   0.   0.  33. 196. 255. 181. 225. 255. 255.]\n",
            " [255. 255. 255. 255. 255. 255. 255. 255. 250. 157. 142. 169. 131. 108.\n",
            "    3.  92.  67.   0.   0.   0. 158. 163. 204. 255. 191. 229. 255. 255.]\n",
            " [255. 255. 255. 255. 255. 255. 255. 118. 227. 234.  78. 120.  47.  19.\n",
            "    5. 128.   0.   0.   0.   0. 248. 255. 255. 255. 255. 255. 255. 255.]\n",
            " [255. 255. 255. 255. 255. 255. 255. 232. 250. 253. 166.  13.   0.   0.\n",
            "    1.  21.   0.   0. 164.  57. 248. 255. 255. 255. 255. 255. 255. 255.]\n",
            " [255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 249. 129.  35. 190.\n",
            "  228.  35.  91. 135. 194. 239. 254. 255. 255. 255. 255. 255. 255. 255.]\n",
            " [255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.\n",
            "  255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.]\n",
            " [255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.\n",
            "  255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.]]\n",
            "(28, 28)\n"
          ]
        }
      ]
    }
  ]
}