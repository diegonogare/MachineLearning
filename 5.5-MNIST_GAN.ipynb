{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMb5j1o3z/ty3czMSqEhiMb"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Usando GAN para gerar novos digitos"
      ],
      "metadata": {
        "id": "25dDKEMx0KL8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Am5PIHUC0Cp9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "#from tqdm import tqdm\n",
        "\n",
        "from keras.layers import Input\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers.core import Dense, Dropout\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.datasets import mnist\n",
        "from keras.optimizers import Adam\n",
        "from keras import initializers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "\n",
        "np.random.seed(42)\n",
        "random_dim = 100"
      ],
      "metadata": {
        "id": "LpciGJ_D0dnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train = (X_train.astype(np.float32) - 127.5)/127.5  \n",
        "X_train = X_train.reshape(60000, 784)"
      ],
      "metadata": {
        "id": "0nbV7JSc0kgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "otimizador = Adam(lr=0.0002, beta_1=0.5)"
      ],
      "metadata": {
        "id": "cBKc4ern1Gac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gerador = Sequential()\n",
        "gerador.add(Dense(256, input_dim=random_dim, kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n",
        "gerador.add(LeakyReLU(0.2))\n",
        "\n",
        "gerador.add(Dense(512))\n",
        "gerador.add(LeakyReLU(0.2))\n",
        "\n",
        "gerador.add(Dense(1024))\n",
        "gerador.add(LeakyReLU(0.2))\n",
        "\n",
        "gerador.add(Dense(784, activation='tanh'))\n",
        "gerador.compile(loss='binary_crossentropy', optimizer=otimizador)"
      ],
      "metadata": {
        "id": "YASk6fSS1W_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminador = Sequential()\n",
        "discriminador.add(Dense(1024, input_dim=784, kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n",
        "discriminador.add(LeakyReLU(0.2))\n",
        "discriminador.add(Dropout(0.3))\n",
        "\n",
        "discriminador.add(Dense(512))\n",
        "discriminador.add(LeakyReLU(0.2))\n",
        "discriminador.add(Dropout(0.3))\n",
        "\n",
        "discriminador.add(Dense(256))\n",
        "discriminador.add(LeakyReLU(0.2))\n",
        "discriminador.add(Dropout(0.3))\n",
        "\n",
        "discriminador.add(Dense(1, activation='sigmoid'))\n",
        "discriminador.compile(loss='binary_crossentropy', optimizer=otimizador)"
      ],
      "metadata": {
        "id": "Cf8prOt51XF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gerar_gan(discriminador, randomDim, gerador, otimizador):\n",
        "  discriminador.trainable = False\n",
        "  gan_input = Input(shape=(random_dim,))\n",
        "  x = gerador(gan_input)\n",
        "\n",
        "  gan_output = discriminador(x)\n",
        "  gan = Model(inputs=gan_input, outputs=gan_output)\n",
        "  gan.compile(loss='binary_crossentropy', optimizer=otimizador)\n",
        "\n",
        "  return gan"
      ],
      "metadata": {
        "id": "3lw0fqSv1rRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def salvar_digito_gerado(epoca, exemplos=25, dim=(5, 5), figsize=(10, 10)):\n",
        "    noise = np.random.normal(0, 1, size=[exemplos, random_dim])\n",
        "    imagem_gerada = gerador.predict(noise)\n",
        "    imagem_gerada = imagem_gerada.reshape(exemplos, 28, 28)\n",
        "\n",
        "    plt.figure(figsize=figsize)\n",
        "    for i in range(imagem_gerada.shape[0]):\n",
        "        plt.subplot(dim[0], dim[1], i+1)\n",
        "        plt.imshow(imagem_gerada[i], interpolation='nearest', cmap='gray_r')\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('gan_digito_gerado_epoca_%d.png' % epoca)"
      ],
      "metadata": {
        "id": "LX9DS__G1rUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 800\n",
        "batchSize = 128\n",
        "\n",
        "gLosses = []\n",
        "dLosses = []\n",
        "\n",
        "batch_count = X_train.shape[0] / batchSize\n",
        "\n",
        "generator = gerador\n",
        "gan = gerar_gan(discriminador, random_dim, gerador, otimizador)\n",
        "\n",
        "batchCount = X_train.shape[0] / batchSize\n",
        "print('Épocas:', epochs)\n",
        "print('Batch size:', batchSize)\n",
        "print('Batches por época:', batchCount)\n",
        "\n",
        "for e in range(1, epochs+1):\n",
        "    print('-'*15, 'Época %d' % e, '-'*15)\n",
        "\n",
        "    noise = np.random.normal(0, 1, size=[batchSize, random_dim])\n",
        "    imageBatch = X_train[np.random.randint(0, X_train.shape[0], size=batchSize)]\n",
        "\n",
        "    imagemGerada = gerador.predict(noise)\n",
        "    X = np.concatenate([imageBatch, imagemGerada])\n",
        "\n",
        "    yDis = np.zeros(2*batchSize)\n",
        "    yDis[:batchSize] = 0.9\n",
        "\n",
        "    discriminador.trainable = True\n",
        "    dloss = discriminador.train_on_batch(X, yDis)\n",
        "\n",
        "    yGen = np.ones(batchSize)\n",
        "    discriminador.trainable = False\n",
        "    gloss = gan.train_on_batch(noise, yGen)\n",
        "\n",
        "    gLosses.append(gloss)\n",
        "    dLosses.append(dloss)\n",
        "\n",
        "    salvar_digito_gerado(e)"
      ],
      "metadata": {
        "id": "q3OHMhVV1rXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gerador.save('GAN_gerador_MNIST.h5')\n",
        "discriminador.save('GAN_discriminador_MNIST.h5')"
      ],
      "metadata": {
        "id": "CZj4HlaWAU-s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}